{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f920a5-cb28-47d6-a57a-b0bcabc88119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f75a8da-4af4-4bb6-9278-c86eb7a44032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define column headers\n",
    "headers = ['unit_number','time_in_cycles','setting_1','setting_2','setting_3','T2','T24','T30','T50','P2','P15','P30','Nf',\n",
    "           'Nc','epr','Ps30','phi','NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ce3ff8-7239-42ff-9d5e-8c9ffb55fbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Swap out the file names below with the FD you would like to e\n",
    "# Read the training data\n",
    "train_file_path = 'train_FD001.txt'\n",
    "train_data = pd.read_csv(train_file_path, delim_whitespace=True, header=None, names=headers)\n",
    "\n",
    "# Read the test data\n",
    "test_file_path = 'test_FD001.txt'\n",
    "test_data = pd.read_csv(test_file_path, delim_whitespace=True, header=None, names=headers)\n",
    "\n",
    "# Read the RUL data\n",
    "rul_file_path = 'RUL_FD001.txt'\n",
    "rul_data = pd.read_csv(rul_file_path, header=None, names=['RUL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "348828d1-e6bd-4528-915c-8afd249698d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the maximum cycle number for each unit in the training data\n",
    "max_cycle_train = train_data.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "max_cycle_train.columns = ['unit_number', 'max_cycle']\n",
    "\n",
    "# Merge the max_cycle_train dataframe with the train data to calculate the RUL for each entry\n",
    "train_data = train_data.merge(max_cycle_train, on='unit_number', how='left')\n",
    "\n",
    "# Calculate the RUL for each entry in the train data\n",
    "train_data['RUL'] = train_data['max_cycle'] - train_data['time_in_cycles']\n",
    "\n",
    "# Drop the temporary max_cycle column\n",
    "train_data = train_data.drop(columns=['max_cycle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2474f0c-bff6-4d90-8c8f-d896e89ccb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T50</th>\n",
       "      <th>P2</th>\n",
       "      <th>...</th>\n",
       "      <th>NRf</th>\n",
       "      <th>NRc</th>\n",
       "      <th>BPR</th>\n",
       "      <th>farB</th>\n",
       "      <th>htBleed</th>\n",
       "      <th>Nf_dmd</th>\n",
       "      <th>PCNfR_dmd</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.75</td>\n",
       "      <td>1602.38</td>\n",
       "      <td>1422.78</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8117.69</td>\n",
       "      <td>8.5207</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.51</td>\n",
       "      <td>22.9588</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>644.18</td>\n",
       "      <td>1596.17</td>\n",
       "      <td>1428.01</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.33</td>\n",
       "      <td>8117.51</td>\n",
       "      <td>8.5183</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.48</td>\n",
       "      <td>23.1127</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.64</td>\n",
       "      <td>1599.22</td>\n",
       "      <td>1425.95</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.35</td>\n",
       "      <td>8112.58</td>\n",
       "      <td>8.5223</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>23.0675</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.34</td>\n",
       "      <td>1602.36</td>\n",
       "      <td>1425.77</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.30</td>\n",
       "      <td>8114.61</td>\n",
       "      <td>8.5174</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.45</td>\n",
       "      <td>23.1295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1601.41</td>\n",
       "      <td>1427.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.32</td>\n",
       "      <td>8110.93</td>\n",
       "      <td>8.5113</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.48</td>\n",
       "      <td>22.9649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_number  time_in_cycles  setting_1  setting_2  setting_3      T2  \\\n",
       "0              1               1    -0.0007    -0.0004      100.0  518.67   \n",
       "1              1               2     0.0019    -0.0003      100.0  518.67   \n",
       "2              1               3    -0.0043     0.0003      100.0  518.67   \n",
       "3              1               4     0.0007     0.0000      100.0  518.67   \n",
       "4              1               5    -0.0019    -0.0002      100.0  518.67   \n",
       "..           ...             ...        ...        ...        ...     ...   \n",
       "187            1             188    -0.0067     0.0003      100.0  518.67   \n",
       "188            1             189    -0.0006     0.0002      100.0  518.67   \n",
       "189            1             190    -0.0027     0.0001      100.0  518.67   \n",
       "190            1             191    -0.0000    -0.0004      100.0  518.67   \n",
       "191            1             192     0.0009    -0.0000      100.0  518.67   \n",
       "\n",
       "        T24      T30      T50     P2  ...      NRf      NRc     BPR  farB  \\\n",
       "0    641.82  1589.70  1400.60  14.62  ...  2388.02  8138.62  8.4195  0.03   \n",
       "1    642.15  1591.82  1403.14  14.62  ...  2388.07  8131.49  8.4318  0.03   \n",
       "2    642.35  1587.99  1404.20  14.62  ...  2388.03  8133.23  8.4178  0.03   \n",
       "3    642.35  1582.79  1401.87  14.62  ...  2388.08  8133.83  8.3682  0.03   \n",
       "4    642.37  1582.85  1406.22  14.62  ...  2388.04  8133.80  8.4294  0.03   \n",
       "..      ...      ...      ...    ...  ...      ...      ...     ...   ...   \n",
       "187  643.75  1602.38  1422.78  14.62  ...  2388.23  8117.69  8.5207  0.03   \n",
       "188  644.18  1596.17  1428.01  14.62  ...  2388.33  8117.51  8.5183  0.03   \n",
       "189  643.64  1599.22  1425.95  14.62  ...  2388.35  8112.58  8.5223  0.03   \n",
       "190  643.34  1602.36  1425.77  14.62  ...  2388.30  8114.61  8.5174  0.03   \n",
       "191  643.54  1601.41  1427.20  14.62  ...  2388.32  8110.93  8.5113  0.03   \n",
       "\n",
       "     htBleed  Nf_dmd  PCNfR_dmd    W31      W32  RUL  \n",
       "0        392    2388      100.0  39.06  23.4190  191  \n",
       "1        392    2388      100.0  39.00  23.4236  190  \n",
       "2        390    2388      100.0  38.95  23.3442  189  \n",
       "3        392    2388      100.0  38.88  23.3739  188  \n",
       "4        393    2388      100.0  38.90  23.4044  187  \n",
       "..       ...     ...        ...    ...      ...  ...  \n",
       "187      396    2388      100.0  38.51  22.9588    4  \n",
       "188      395    2388      100.0  38.48  23.1127    3  \n",
       "189      398    2388      100.0  38.49  23.0675    2  \n",
       "190      394    2388      100.0  38.45  23.1295    1  \n",
       "191      396    2388      100.0  38.48  22.9649    0  \n",
       "\n",
       "[192 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['unit_number']==1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6bfd591-6098-40ad-9d53-074b3bef50c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rul_data.columns = ['RUL']\n",
    "rul_data['unit_number'] = rul_data.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d733d5c8-5b35-4234-b81b-3beef0e1a600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T50</th>\n",
       "      <th>P2</th>\n",
       "      <th>...</th>\n",
       "      <th>NRf</th>\n",
       "      <th>NRc</th>\n",
       "      <th>BPR</th>\n",
       "      <th>farB</th>\n",
       "      <th>htBleed</th>\n",
       "      <th>Nf_dmd</th>\n",
       "      <th>PCNfR_dmd</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>100</td>\n",
       "      <td>194</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.24</td>\n",
       "      <td>1599.45</td>\n",
       "      <td>1415.79</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8213.28</td>\n",
       "      <td>8.4715</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.65</td>\n",
       "      <td>23.1974</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>100</td>\n",
       "      <td>195</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.22</td>\n",
       "      <td>1595.69</td>\n",
       "      <td>1422.05</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8210.85</td>\n",
       "      <td>8.4512</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.57</td>\n",
       "      <td>23.2771</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.44</td>\n",
       "      <td>1593.15</td>\n",
       "      <td>1406.82</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8217.24</td>\n",
       "      <td>8.4569</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.62</td>\n",
       "      <td>23.2051</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.26</td>\n",
       "      <td>1594.99</td>\n",
       "      <td>1419.36</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8220.48</td>\n",
       "      <td>8.4711</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.66</td>\n",
       "      <td>23.2699</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.95</td>\n",
       "      <td>1601.62</td>\n",
       "      <td>1424.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8214.64</td>\n",
       "      <td>8.4903</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>23.1855</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13096 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit_number  time_in_cycles  setting_1  setting_2  setting_3      T2  \\\n",
       "0                1               1     0.0023     0.0003      100.0  518.67   \n",
       "1                1               2    -0.0027    -0.0003      100.0  518.67   \n",
       "2                1               3     0.0003     0.0001      100.0  518.67   \n",
       "3                1               4     0.0042     0.0000      100.0  518.67   \n",
       "4                1               5     0.0014     0.0000      100.0  518.67   \n",
       "...            ...             ...        ...        ...        ...     ...   \n",
       "13091          100             194     0.0049     0.0000      100.0  518.67   \n",
       "13092          100             195    -0.0011    -0.0001      100.0  518.67   \n",
       "13093          100             196    -0.0006    -0.0003      100.0  518.67   \n",
       "13094          100             197    -0.0038     0.0001      100.0  518.67   \n",
       "13095          100             198     0.0013     0.0003      100.0  518.67   \n",
       "\n",
       "          T24      T30      T50     P2  ...      NRf      NRc     BPR  farB  \\\n",
       "0      643.02  1585.29  1398.21  14.62  ...  2388.03  8125.55  8.4052  0.03   \n",
       "1      641.71  1588.45  1395.42  14.62  ...  2388.06  8139.62  8.3803  0.03   \n",
       "2      642.46  1586.94  1401.34  14.62  ...  2388.03  8130.10  8.4441  0.03   \n",
       "3      642.44  1584.12  1406.42  14.62  ...  2388.05  8132.90  8.3917  0.03   \n",
       "4      642.51  1587.19  1401.92  14.62  ...  2388.03  8129.54  8.4031  0.03   \n",
       "...       ...      ...      ...    ...  ...      ...      ...     ...   ...   \n",
       "13091  643.24  1599.45  1415.79  14.62  ...  2388.00  8213.28  8.4715  0.03   \n",
       "13092  643.22  1595.69  1422.05  14.62  ...  2388.09  8210.85  8.4512  0.03   \n",
       "13093  643.44  1593.15  1406.82  14.62  ...  2388.04  8217.24  8.4569  0.03   \n",
       "13094  643.26  1594.99  1419.36  14.62  ...  2388.08  8220.48  8.4711  0.03   \n",
       "13095  642.95  1601.62  1424.99  14.62  ...  2388.05  8214.64  8.4903  0.03   \n",
       "\n",
       "       htBleed  Nf_dmd  PCNfR_dmd    W31      W32    RUL  \n",
       "0          392    2388      100.0  38.86  23.3735  142.0  \n",
       "1          393    2388      100.0  39.02  23.3916  141.0  \n",
       "2          393    2388      100.0  39.08  23.4166  140.0  \n",
       "3          391    2388      100.0  39.00  23.3737  139.0  \n",
       "4          390    2388      100.0  38.99  23.4130  138.0  \n",
       "...        ...     ...        ...    ...      ...    ...  \n",
       "13091      394    2388      100.0  38.65  23.1974   24.0  \n",
       "13092      395    2388      100.0  38.57  23.2771   23.0  \n",
       "13093      395    2388      100.0  38.62  23.2051   22.0  \n",
       "13094      395    2388      100.0  38.66  23.2699   21.0  \n",
       "13095      396    2388      100.0  38.70  23.1855   20.0  \n",
       "\n",
       "[13096 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the maximum cycle number for each unit in the test data\n",
    "max_cycle_test = test_data.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "max_cycle_test.columns = ['unit_number', 'max_cycle']\n",
    "\n",
    "# Merge the max_cycle_test dataframe with the test data to calculate the RUL for each entry\n",
    "test_data = test_data.merge(max_cycle_test, on='unit_number', how='left')\n",
    "\n",
    "# Assign the RUL values to the test data based on unit number\n",
    "# The provided RUL is at the end of the data collection, add this RUL to the difference between max cycle and current cycle\n",
    "test_data['RUL'] = test_data.apply(lambda row: rul_data.loc[rul_data['unit_number'] == row['unit_number'], 'RUL'].values[0] + (row['max_cycle'] - row['time_in_cycles']), axis=1)\n",
    "\n",
    "# Drop the temporary max_cycle column\n",
    "test_data = test_data.drop(columns=['max_cycle'])\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a643beec-e21e-4afe-9955-e7142947e30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the data for training\n",
    "X_train = train_data.drop(columns=['unit_number', 'time_in_cycles', 'RUL'])\n",
    "y_train = train_data[['unit_number', 'time_in_cycles', 'RUL']]\n",
    "X_test = test_data.drop(columns=['unit_number', 'time_in_cycles', 'RUL'])\n",
    "y_test = test_data[['unit_number', 'time_in_cycles', 'RUL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "690960ab-3d97-4d3d-bbe2-62361586b4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Lasso: {'alpha': 0.01}\n",
      "Best R^2 for Lasso: 0.5691915070178621\n",
      "Lasso Regression - MAE: 25.655149278725222, MSE: 1029.813594041371, R^2: 0.40365294864107215\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Lasso\n",
    "lasso_params = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Lasso Regression with GridSearchCV\n",
    "lasso = Lasso()\n",
    "lasso_cv = GridSearchCV(lasso, lasso_params, cv=5, scoring='r2')\n",
    "lasso_cv.fit(X_train, y_train['RUL'])\n",
    "\n",
    "# Best alpha and R^2 score for Lasso\n",
    "print(f\"Best alpha for Lasso: {lasso_cv.best_params_}\")\n",
    "print(f\"Best R^2 for Lasso: {lasso_cv.best_score_}\")\n",
    "\n",
    "# Filter test data to get the rows with the maximum time_in_cycles for each unit_number\n",
    "max_cycles = test_data.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "test_max_cycles = pd.merge(test_data, max_cycles, on=['unit_number', 'time_in_cycles'], how='inner')\n",
    "\n",
    "# Evaluate Lasso on filtered test data\n",
    "test_max_cycles.loc[:, 'predicted'] = lasso_cv.predict(test_max_cycles.drop(columns=['unit_number', 'time_in_cycles', 'RUL']))\n",
    "mae_lasso = mean_absolute_error(test_max_cycles['RUL'], test_max_cycles['predicted'])\n",
    "mse_lasso = mean_squared_error(test_max_cycles['RUL'], test_max_cycles['predicted'])\n",
    "r2_lasso = r2_score(test_max_cycles['RUL'], test_max_cycles['predicted'])\n",
    "\n",
    "print(f\"Lasso Regression - MAE: {mae_lasso}, MSE: {mse_lasso}, R^2: {r2_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ea49913-9cc7-4cf8-802d-3bd9f29f17bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Ridge: {'alpha': 1}\n",
      "Best R^2 for Ridge: 0.5692086558760463\n",
      "Ridge Regression - MAE: 25.554324770372187, MSE: 1021.8607774746306, R^2: 0.40825828570111444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Ridge\n",
    "ridge_params = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Ridge Regression with GridSearchCV\n",
    "ridge = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge, ridge_params, cv=5, scoring='r2')\n",
    "ridge_cv.fit(X_train, y_train['RUL'])\n",
    "\n",
    "# Best alpha and R^2 score for Ridge\n",
    "print(f\"Best alpha for Ridge: {ridge_cv.best_params_}\")\n",
    "print(f\"Best R^2 for Ridge: {ridge_cv.best_score_}\")\n",
    "\n",
    "# Filter test data to get the rows with the maximum time_in_cycles for each unit_number\n",
    "max_cycles = test_data.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "test_max_cycles = pd.merge(test_data, max_cycles, on=['unit_number', 'time_in_cycles'], how='inner')\n",
    "\n",
    "# Evaluate Ridge on filtered test data\n",
    "test_max_cycles.loc[:, 'predicted'] = ridge_cv.predict(test_max_cycles.drop(columns=['unit_number', 'time_in_cycles', 'RUL']))\n",
    "mae_ridge = mean_absolute_error(test_max_cycles['RUL'], test_max_cycles['predicted'])\n",
    "mse_ridge = mean_squared_error(test_max_cycles['RUL'], test_max_cycles['predicted'])\n",
    "r2_ridge = r2_score(test_max_cycles['RUL'], test_max_cycles['predicted'])\n",
    "\n",
    "print(f\"Ridge Regression - MAE: {mae_ridge}, MSE: {mse_ridge}, R^2: {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30f163fe-bae2-4a43-9446-9e5c33fd2a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1026.631754812678\n",
      "R^2 Score: 0.4054954961204492\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train['RUL'])\n",
    "\n",
    "# Filter test data to get the rows with the maximum time_in_cycles for each unit_number\n",
    "max_cycles = test_data.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "test_max_cycles = pd.merge(test_data, max_cycles, on=['unit_number', 'time_in_cycles'], how='inner')\n",
    "\n",
    "# Predict on the filtered test set\n",
    "y_pred = model.predict(test_max_cycles.drop(columns=['unit_number', 'time_in_cycles', 'RUL']))\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(test_max_cycles['RUL'], y_pred)\n",
    "r2 = r2_score(test_max_cycles['RUL'], y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db714f71-6121-43a2-be1d-7a0bc9b7e8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e4d5851-2b1f-43fa-ad3a-6b07395dc576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maggi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer for regression task\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e69e848c-4858-4d52-bde2-01bc219ee32b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8767.8252 - mae: 71.3803 - val_loss: 2811.3057 - val_mae: 39.7318\n",
      "Epoch 2/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 1735.1287 - mae: 30.6692 - val_loss: 2762.9495 - val_mae: 38.3313\n",
      "Epoch 3/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 1576.4919 - mae: 28.5086 - val_loss: 2670.9431 - val_mae: 37.1054\n",
      "Epoch 4/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 1556.2882 - mae: 28.0270 - val_loss: 2748.1692 - val_mae: 37.3693\n",
      "Epoch 5/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 1491.5320 - mae: 27.3344 - val_loss: 2786.1599 - val_mae: 37.6204\n",
      "Epoch 6/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 1547.7172 - mae: 27.7833 - val_loss: 2529.0029 - val_mae: 36.3914\n",
      "Epoch 7/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 1485.9459 - mae: 27.3283 - val_loss: 2705.0378 - val_mae: 37.0977\n",
      "Epoch 8/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 1476.3608 - mae: 27.2271 - val_loss: 2642.8621 - val_mae: 36.7446\n",
      "Epoch 9/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 1464.0940 - mae: 27.1562 - val_loss: 2790.7168 - val_mae: 37.4097\n",
      "Epoch 10/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 1513.7263 - mae: 27.3002 - val_loss: 2609.5110 - val_mae: 36.6047\n",
      "Epoch 11/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 1444.9989 - mae: 26.9015 - val_loss: 2725.2649 - val_mae: 37.1830\n",
      "Epoch 12/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 1442.4086 - mae: 26.5572 - val_loss: 2522.8872 - val_mae: 36.3815\n",
      "Epoch 13/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 1473.2731 - mae: 26.8972 - val_loss: 2592.7637 - val_mae: 36.5304\n",
      "Epoch 14/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 1451.5164 - mae: 26.9226 - val_loss: 2632.1199 - val_mae: 36.8232\n",
      "Epoch 15/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 1458.4553 - mae: 26.7660 - val_loss: 2653.1216 - val_mae: 36.8964\n",
      "Epoch 16/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 1442.5264 - mae: 26.6724 - val_loss: 2559.9277 - val_mae: 36.4515\n",
      "Epoch 17/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 1445.2571 - mae: 26.5868 - val_loss: 2588.3884 - val_mae: 36.6407\n",
      "Epoch 18/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 1435.2141 - mae: 26.5944 - val_loss: 2615.0884 - val_mae: 36.7345\n",
      "Epoch 19/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 1418.5967 - mae: 26.2777 - val_loss: 2579.1135 - val_mae: 36.4704\n",
      "Epoch 20/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 1428.4965 - mae: 26.6567 - val_loss: 2580.4268 - val_mae: 36.7106\n",
      "Epoch 21/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 1426.6980 - mae: 26.6278 - val_loss: 2546.8950 - val_mae: 36.4878\n",
      "Epoch 22/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 1460.9384 - mae: 26.6697 - val_loss: 2717.1370 - val_mae: 37.0276\n",
      "Epoch 23/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 1503.2781 - mae: 27.0300 - val_loss: 2597.8845 - val_mae: 36.6026\n",
      "Epoch 24/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 1429.5848 - mae: 26.6845 - val_loss: 2636.8440 - val_mae: 36.7744\n",
      "Epoch 25/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 1440.6833 - mae: 26.5635 - val_loss: 2641.1372 - val_mae: 36.8992\n",
      "Epoch 26/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 1422.3062 - mae: 26.5649 - val_loss: 2685.0815 - val_mae: 37.0759\n",
      "Epoch 27/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 1418.4911 - mae: 26.4169 - val_loss: 2581.9966 - val_mae: 36.5355\n",
      "Epoch 28/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 1444.0994 - mae: 26.6251 - val_loss: 2488.9321 - val_mae: 36.2908\n",
      "Epoch 29/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 1434.9156 - mae: 26.7245 - val_loss: 2607.7180 - val_mae: 36.6828\n",
      "Epoch 30/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 1491.9719 - mae: 27.0756 - val_loss: 2646.7288 - val_mae: 37.1105\n",
      "Epoch 31/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 1423.3113 - mae: 26.4038 - val_loss: 2668.0427 - val_mae: 37.1223\n",
      "Epoch 32/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 1441.2463 - mae: 26.5625 - val_loss: 2588.6865 - val_mae: 36.5599\n",
      "Epoch 33/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 1440.2914 - mae: 26.6460 - val_loss: 2689.9714 - val_mae: 37.0069\n",
      "Epoch 34/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 1465.1179 - mae: 26.8528 - val_loss: 2636.2090 - val_mae: 36.7557\n",
      "Epoch 35/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 1434.0095 - mae: 26.4908 - val_loss: 2586.4319 - val_mae: 36.4402\n",
      "Epoch 36/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 1437.6687 - mae: 26.5887 - val_loss: 2713.6184 - val_mae: 37.1636\n",
      "Epoch 37/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 1431.4431 - mae: 26.6821 - val_loss: 2612.7502 - val_mae: 36.6427\n",
      "Epoch 38/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 1423.9445 - mae: 26.4981 - val_loss: 2737.9165 - val_mae: 37.5187\n",
      "Epoch 39/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 1402.5304 - mae: 26.3295 - val_loss: 2680.7566 - val_mae: 37.0249\n",
      "Epoch 40/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 1393.1841 - mae: 26.3694 - val_loss: 2645.4114 - val_mae: 36.8819\n",
      "Epoch 41/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 1382.7675 - mae: 26.2792 - val_loss: 2535.4700 - val_mae: 36.3506\n",
      "Epoch 42/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 1391.6896 - mae: 26.2935 - val_loss: 2837.0076 - val_mae: 37.8684\n",
      "Epoch 43/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 1467.4607 - mae: 27.0295 - val_loss: 2773.6477 - val_mae: 37.3818\n",
      "Epoch 44/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 1387.9880 - mae: 26.2638 - val_loss: 2615.8589 - val_mae: 36.5768\n",
      "Epoch 45/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 1408.2260 - mae: 26.3759 - val_loss: 2619.6865 - val_mae: 36.6491\n",
      "Epoch 46/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 1400.7655 - mae: 26.2198 - val_loss: 2548.0940 - val_mae: 36.2988\n",
      "Epoch 47/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 1403.4851 - mae: 26.4792 - val_loss: 2568.6418 - val_mae: 36.4181\n",
      "Epoch 48/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 1483.8490 - mae: 26.9762 - val_loss: 2601.6802 - val_mae: 36.5997\n",
      "Epoch 49/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 1418.0984 - mae: 26.5588 - val_loss: 2571.0054 - val_mae: 36.4921\n",
      "Epoch 50/50\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 1423.3988 - mae: 26.4495 - val_loss: 2634.0171 - val_mae: 36.7758\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train['RUL'], epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2c331dd-2dd0-4a16-8491-0f7258bc397d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 959.9179 - mae: 23.3485  \n",
      "Test Accuracy: 22.5759\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 959.9179 - mae: 23.3485  \n",
      "Test Mean Absolute Error: 22.5759\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "R² Value: 0.4696\n"
     ]
    }
   ],
   "source": [
    "# Filter test data to get the rows with the maximum time_in_cycles for each unit_number\n",
    "max_cycles = test_data.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "test_max_cycles = pd.merge(test_data, max_cycles, on=['unit_number', 'time_in_cycles'], how='inner')\n",
    "\n",
    "# Assuming X_test_scaled is the scaled version of X_test, you need to scale test_max_cycles accordingly\n",
    "# Note: Make sure to use the same scaling method used on X_train to scale test_max_cycles\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_test_max_scaled = scaler.transform(test_max_cycles.drop(columns=['unit_number', 'time_in_cycles', 'RUL']))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_max_scaled, test_max_cycles['RUL'])\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "loss, mae = model.evaluate(X_test_max_scaled, test_max_cycles['RUL'])\n",
    "print(f'Test Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_max_scaled)\n",
    "\n",
    "# Calculate the R² value\n",
    "r2 = r2_score(test_max_cycles['RUL'], predictions)\n",
    "print(f'R² Value: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4717ee44-ac47-4846-ab7e-a1ffdf49b0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 31.3662\n",
      "Mean Absolute Error: 23.0233\n",
      "R² Value: 0.4303\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Filter test data to get the rows with the maximum time_in_cycles for each unit_number\n",
    "max_cycles = test_data.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
    "test_max_cycles = pd.merge(test_data, max_cycles, on=['unit_number', 'time_in_cycles'], how='inner')\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_max_scaled = scaler.transform(test_max_cycles.drop(columns=['unit_number', 'time_in_cycles', 'RUL']))\n",
    "\n",
    "# Train the Model\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "\n",
    "xg_reg.fit(X_train_scaled, y_train['RUL'])\n",
    "\n",
    "# Evaluate the Model\n",
    "predictions = xg_reg.predict(X_test_max_scaled)\n",
    "rmse = mean_squared_error(test_max_cycles['RUL'], predictions, squared=False)\n",
    "mae = mean_absolute_error(test_max_cycles['RUL'], predictions)\n",
    "r2 = r2_score(test_max_cycles['RUL'], predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"R² Value: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c2f7d-d31b-497d-ad15-ef10ec17be46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
